{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b004d1d1-a34e-4517-9b01-327efbe2c318",
   "metadata": {},
   "source": [
    "# 4. Append 2024\n",
    "\n",
    "## 4a. List, virtualize and concatenize datasets\n",
    "\n",
    "2023-09-04 to 2023-12-31 chunking:\n",
    "\n",
    "* `sea_ice_fraction` and `mask` from 2023-09-04 to the end of 2023 have chunking (1, 4500, 9000) (previously (1, 1447, 2895))\n",
    "* `analysed_sst` and `analysis_error` from 2023-09-04 to the end of 2023 have chunking (1, 3600, 7200) (previously (1, 1023, 2047))\n",
    "\n",
    "2024 to date chunking:\n",
    "* `sea_ice_fraction` and `mask` start 2024 with chunking (1, 4500, 9000) and then changes on 2024-03-24 to (1, 1023, 2047) - **never seen this chunk shape for these variables before**.\n",
    "* `analysed_sst` and `analysis_error` start 2024 with chunking (1, 3600, 7200) and then changes on 2024-03-24 to (1, 1023, 2047) (original chunking)\n",
    "\n",
    "It would be nice to just append to the existing store, using zarr for 2023-09-04 to sometime in 2024 when it changes, but then we couldn't go back to virtual references since `sea_ice_fraction` and `mask` are using a chunk shape never used before. A combination of zarr + virtual references seems possible but messy. Plus we still have to write over 6 months as zarr.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21525644-b226-4a53-9081-555f54b2b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2024-01-01\", \"2024-12-31\"]\n",
    "mur_sst_files_2024 = helpers.list_mur_sst_files(start_date=dates[0], end_date=dates[1])\n",
    "mur_sst_dmrpps_2024 = [f + '.dmrpp' for f in mur_sst_files_2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07b823a6-595c-46c2-a0ac-abb01a9d3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(mur_sst_dmrpps_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "755e59a5-1bc6-4e42-8998-567b4ac5122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdss = [helpers.open_virtual(f) for f in mur_sst_dmrpps_2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "811f55ac-6966-4340-9bbd-ffeea2e98589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20240324090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\n"
     ]
    }
   ],
   "source": [
    "first_chunk_shape = vdss[0]['analysed_sst'].chunks\n",
    "for vds in vdss:\n",
    "    if vds['analysed_sst'].chunks != first_chunk_shape:\n",
    "        print(vds.analysed_sst.data.manifest.dict()['0.0.0']['path'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b400d55-7460-409d-a99a-bfdcdbde8b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 17:14:35,865 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('from_sequence-open_virtual-reduce_via_concat-part-d183d7f52955da84300603ccd0058afc', 76)\n",
      "State:     executing\n",
      "Task:  <Task ('from_sequence-open_virtual-reduce_via_concat-part-d183d7f52955da84300603ccd0058afc', 76) _execute_subgraph(...)>\n",
      "Exception: \"ValueError('Cannot concatenate arrays with inconsistent chunk shapes: (1, 1023, 2047) vs (1, 4500, 9000) .Requires ZEP003 (Variable-length Chunks).')\"\n",
      "Traceback: '  File \"/opt/conda/lib/python3.11/site-packages/dask/bag/core.py\", line 2504, in empty_safe_apply\\n    return func(part)\\n           ^^^^^^^^^^\\n  File \"/home/jovyan/icechunk-nasa/icechunk-nasa/notebooks/mur-sst/helpers.py\", line 33, in reduce_via_concat\\n    return xr.concat(\\n           ^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/xarray/core/concat.py\", line 277, in concat\\n    return _dataset_concat(\\n           ^^^^^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/xarray/core/concat.py\", line 669, in _dataset_concat\\n    combined_var = concat_vars(\\n                   ^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/xarray/core/variable.py\", line 3058, in concat\\n    return Variable.concat(variables, dim, positions, shortcut, combine_attrs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/xarray/core/variable.py\", line 1787, in concat\\n    data = duck_array_ops.concatenate(arrays, axis=axis)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/xarray/core/duck_array_ops.py\", line 408, in concatenate\\n    return xp.concat(as_shared_dtype(arrays, xp=xp), axis=axis)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/array.py\", line 123, in __array_function__\\n    return MANIFESTARRAY_HANDLED_ARRAY_FUNCTIONS[func](*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/array_api.py\", line 66, in concatenate\\n    check_combinable_zarr_arrays(arrays)\\n  File \"/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/utils.py\", line 109, in check_combinable_zarr_arrays\\n    check_same_chunk_shapes([arr.chunks for arr in arrays])\\n  File \"/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/utils.py\", line 50, in check_same_chunk_shapes\\n    raise ValueError(\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot concatenate arrays with inconsistent chunk shapes: (1, 1023, 2047) vs (1, 4500, 9000) .Requires ZEP003 (Variable-length Chunks).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create the virtual store\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m virtual_ds_2024 \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_virtual_ds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmrpps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmur_sst_dmrpps_2024\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/icechunk-nasa/icechunk-nasa/notebooks/mur-sst/helpers.py:48\u001b[0m, in \u001b[0;36mcreate_virtual_ds\u001b[0;34m(dmrpps, parallel)\u001b[0m\n\u001b[1;32m     46\u001b[0m     vdss \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mmap(open_virtual, db\u001b[38;5;241m.\u001b[39mfrom_sequence(dmrpps))\n\u001b[1;32m     47\u001b[0m     concatted \u001b[38;5;241m=\u001b[39m vdss\u001b[38;5;241m.\u001b[39mreduction(reduce_via_concat, reduce_via_concat)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     vdss \u001b[38;5;241m=\u001b[39m [open_virtual(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m dmrpps]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dask/base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/dask/bag/core.py:2504\u001b[0m, in \u001b[0;36mempty_safe_apply\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m   2503\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m no_result\n\u001b[0;32m-> 2504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(part)\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m no_result\n",
      "File \u001b[0;32m~/icechunk-nasa/icechunk-nasa/notebooks/mur-sst/helpers.py:33\u001b[0m, in \u001b[0;36mreduce_via_concat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce_via_concat\u001b[39m(vdss: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     34\u001b[0m         vdss,\n\u001b[1;32m     35\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m         coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# not sure why neither of those options work as a replacement for drop_vars in open_virtual (but that's probably a better solution)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# data_vars=\"minimal\": Only data variables in which the dimension already appears are included.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# data_vars=list of dims (guessing this should be vars): The listed data variables will be concatenated, in addition to the “minimal” data variables.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# data_vars=['analysed_sst', 'analysis_error', 'mask', 'sea_ice_fraction'],\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xarray/core/concat.py:277\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataarray_concat(\n\u001b[1;32m    265\u001b[0m         objs,\n\u001b[1;32m    266\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m         create_index_for_new_dim\u001b[38;5;241m=\u001b[39mcreate_index_for_new_dim,\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_obj, Dataset):\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataset_concat(\n\u001b[1;32m    278\u001b[0m         objs,\n\u001b[1;32m    279\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    280\u001b[0m         data_vars\u001b[38;5;241m=\u001b[39mdata_vars,\n\u001b[1;32m    281\u001b[0m         coords\u001b[38;5;241m=\u001b[39mcoords,\n\u001b[1;32m    282\u001b[0m         compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[1;32m    283\u001b[0m         positions\u001b[38;5;241m=\u001b[39mpositions,\n\u001b[1;32m    284\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    285\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    286\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    287\u001b[0m         create_index_for_new_dim\u001b[38;5;241m=\u001b[39mcreate_index_for_new_dim,\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xarray/core/concat.py:669\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m()\u001b[0m\n\u001b[1;32m    667\u001b[0m         result_vars[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     combined_var \u001b[38;5;241m=\u001b[39m concat_vars(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;28mvars\u001b[39m, dim_name, positions, combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs\n\u001b[1;32m    671\u001b[0m     )\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;66;03m# reindex if variable is not present in all datasets\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(variable_index) \u001b[38;5;241m<\u001b[39m concat_index_size:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xarray/core/variable.py:3058\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IndexVariable\u001b[38;5;241m.\u001b[39mconcat(variables, dim, positions, shortcut, combine_attrs)\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39mconcat(variables, dim, positions, shortcut, combine_attrs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xarray/core/variable.py:1787\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1785\u001b[0m axis \u001b[38;5;241m=\u001b[39m first_var\u001b[38;5;241m.\u001b[39mget_axis_num(dim)\n\u001b[1;32m   1786\u001b[0m dims \u001b[38;5;241m=\u001b[39m first_var_dims\n\u001b[0;32m-> 1787\u001b[0m data \u001b[38;5;241m=\u001b[39m duck_array_ops\u001b[38;5;241m.\u001b[39mconcatenate(arrays, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1789\u001b[0m     \u001b[38;5;66;03m# TODO: deprecate this option -- we don't need it for groupby\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# any more.\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     indices \u001b[38;5;241m=\u001b[39m nputils\u001b[38;5;241m.\u001b[39minverse_permutation(np\u001b[38;5;241m.\u001b[39mconcatenate(positions))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/xarray/core/duck_array_ops.py:408\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m xp \u001b[38;5;241m=\u001b[39m get_array_namespace(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mconcat(as_shared_dtype(arrays, xp\u001b[38;5;241m=\u001b[39mxp), axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mconcatenate(as_shared_dtype(arrays, xp\u001b[38;5;241m=\u001b[39mxp), axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/array.py:123\u001b[0m, in \u001b[0;36m__array_function__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28missubclass\u001b[39m(t, ManifestArray) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MANIFESTARRAY_HANDLED_ARRAY_FUNCTIONS[func](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/array_api.py:66\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# ensure dtypes, shapes, codecs etc. are consistent\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m check_combinable_zarr_arrays(arrays)\n\u001b[1;32m     68\u001b[0m check_same_ndims([arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays])\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Ensure we handle axis being passed as a negative integer\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/utils.py:109\u001b[0m, in \u001b[0;36mcheck_combinable_zarr_arrays\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m check_same_codecs([get_codecs(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays])\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Would require variable-length chunks ZEP\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m check_same_chunk_shapes([arr\u001b[38;5;241m.\u001b[39mchunks \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/virtualizarr/manifests/utils.py:50\u001b[0m, in \u001b[0;36mcheck_same_chunk_shapes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other_chunks \u001b[38;5;129;01min\u001b[39;00m other_chunks_list:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other_chunks \u001b[38;5;241m!=\u001b[39m first_chunks:\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot concatenate arrays with inconsistent chunk shapes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m .\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequires ZEP003 (Variable-length Chunks).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot concatenate arrays with inconsistent chunk shapes: (1, 1023, 2047) vs (1, 4500, 9000) .Requires ZEP003 (Variable-length Chunks)."
     ]
    }
   ],
   "source": [
    "# create the virtual store\n",
    "virtual_ds_2024 = helpers.create_virtual_ds(dmrpps=mur_sst_dmrpps_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fd4ae-bf49-4520-88ab-1f4df4c3f425",
   "metadata": {},
   "source": [
    "## 3b. Write to icechunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b6b2e-e088-4d17-92c1-06e54a12ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "session = repo.writable_session(branch=\"main\")\n",
    "store = session.store\n",
    "virtual_ds_2024.virtualize.to_icechunk(store)\n",
    "session.commit(\"Wrote 2024 data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9649c-36e9-401b-972c-c9e90a896eb0",
   "metadata": {},
   "source": [
    "## 3c. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75209b-be4b-4187-adee-826408dc9e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "helpers.validate_data(store, dates=dates, fs=fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
